{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I lived in the city of Austin, Texas for 4 years. I personally saw how the city was increasing in different types of businesses. However, Austin is a small city which can make it difficult to place new businesses in already crowded locations like downtown. The crowdedness in a single area is not the only concern, but that single area can also have similar types of businesses. \n",
    "\n",
    "In this report I will cluster similar venues around the different zip codes in Austin. New business owners should then be able to use this report to stratigically place their new business in Austin. With the help of <b>Foursquare</b>, we should be able to: see the amount of businesses in an area, the types of businesses, and the most common venues of an area.\n",
    "\n",
    "<i>This report should not be used as the main decision maker on placing a new business in austin.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be similar to the data used in the IBM course, which consists of: Zip Code, Longitude, Latitude, Venue, and Venue Category. \n",
    "\n",
    "I will collect data from https://www.zip-codes.com/m/city/tx-austin.asp which has the zip codes for Austin. I will also collect the latitude and longitude from this website with the use of a function.\n",
    "\n",
    "<b>Foursquare</b> will then provide me with the venue data around the zip codes. \n",
    "\n",
    "The Latitude and Longitude data will be used by the library <b>Folium</b> so a map and the markers can be created.\n",
    "\n",
    "The idea would be to have a dataframe like below:\n",
    "\n",
    "|Index|ZipCode|Latitude|Longitude|1st Common Venue| 2nd Common Venue| ... | 10th Common Venue|\n",
    "|-----|-------|--------|---------|----------------|-----------------|-----|------------------|\n",
    "|0    |NA     |NA      |NA       |NA              |NA               | ... |NA                |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Done] Introduction where you discuss the business problem and who would be interested in this project.\n",
    "\n",
    "[Done] Data where you describe the data that will be used to solve the problem and the source of the data.\n",
    "\n",
    "Methodology section which represents the main component of the report where you discuss and describe any exploratory data analysis that you did, any inferential statistical testing that you performed, and what machine learnings were used and why.\n",
    "\n",
    "Results section where you discuss the results.\n",
    "\n",
    "Discussion section where you discuss any observations you noted and any recommendations you can make based on the results.\n",
    "\n",
    "Conclusion section where you conclude the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries from the \"Segmenting and Clustering Neighborhoods in New York City\" lab\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Importing the Web Scraping libraries\n",
    "# Install these into your system/environment if not downloaded\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "\n",
    "def get_content(url):\n",
    "    #Create a handle, page, to handle the contents of the website\n",
    "    page = requests.get(url)\n",
    "    #Store the contents of the website under doc\n",
    "    doc = lh.fromstring(page.content)\n",
    "    return doc\n",
    "\n",
    "def get_coord(zip_code):\n",
    "    url = 'https://www.zip-codes.com/m/zip-code/' + zip_code + '/zip-code-' + zip_code + '.asp'\n",
    "    zipDoc = get_content(url)\n",
    "    tr_elements2 = zipDoc.xpath('//tr')\n",
    "    lat = tr_elements2[11].text_content()[9:]\n",
    "    long = tr_elements2[12].text_content()[10:]\n",
    "\n",
    "# The url for the wiki page\n",
    "url = 'https://www.zip-codes.com/m/city/tx-austin.asp'\n",
    "doc = get_content(url)\n",
    "\n",
    "#Parse data that are stored between <tr>..</tr> of HTML\n",
    "tr_elements = doc.xpath('//tr')\n",
    "\n",
    "#Create empty list\n",
    "col=[]\n",
    "i=0\n",
    "\n",
    "# Geting Column Names\n",
    "for t in tr_elements[0]:\n",
    "    i+=1\n",
    "    name=t.text_content()\n",
    "    col.append((name,[]))\n",
    "\n",
    "# Getting the values for each columns\n",
    "for j in range(1,len(tr_elements)):\n",
    "    #T is our j'th row\n",
    "    T=tr_elements[j]\n",
    "    \n",
    "    #If row is not of size 4, the //tr data is not from our table \n",
    "    if len(T)!=4:\n",
    "        break\n",
    "    \n",
    "    #i is the index of our column\n",
    "    i=0\n",
    "    \n",
    "    #Iterate through each element of the row\n",
    "    for t in T.iterchildren():\n",
    "        data=t.text_content() \n",
    "        #Check if row is empty\n",
    "        if i>0:\n",
    "        #Convert any numerical value to integers\n",
    "            try:\n",
    "                data=int(data)\n",
    "            except:\n",
    "                pass\n",
    "        #Append the data to the empty list of the i'th column\n",
    "        col[i][1].append(data)\n",
    "        #Increment i for the next column\n",
    "        i+=1\n",
    "\n",
    "Dict={title:column for (title,column) in col}\n",
    "df=pd.DataFrame(Dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
